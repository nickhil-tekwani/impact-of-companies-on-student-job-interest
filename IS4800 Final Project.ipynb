{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/nickhiltekwani/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/nickhiltekwani/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/nickhiltekwani/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import nan\n",
    "import math\n",
    "import text2emotion as te\n",
    "import nltk\n",
    "# nltk.download('omw-1.4')\n",
    "from autocorrect import Speller \n",
    "spell = Speller(lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autospell(text):\n",
    "        \"\"\"\n",
    "        correct the spelling of the word.\n",
    "        \"\"\"\n",
    "        spells = [spell(w) for w in (nltk.word_tokenize(text))]\n",
    "        return \" \".join(spells) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/nickhiltekwani/Downloads/AI Industry Study (Responses) - Form Responses 1.csv')\n",
    "df = df.drop('Timestamp', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no previous question\n",
    "ai_experience = \"If you would like, please describe your experience with AI or knowledge surrounding it\"\n",
    "\n",
    "# Do you feel that your computer or data science undergraduate education has properly prepared you for a career in Al?\n",
    "prepared_for_ai = \"Please expand on the previous question if you are a CS, DS, IS, or Cybersecurity major\"\n",
    "\n",
    "# Regardless of major, do your undergrad courses discuss job opportunities/industries that \n",
    "# you can explore with the tools that course/your major teaches you?\n",
    "discuss_jobs = \"Please expand on the previous question, regardless of major\"\n",
    "\n",
    "# If you are a computer or data science major, do you feel that your courses properly prepared you for your internship? \n",
    "prepared_for_internship = \"If applicable, please expand on the previous question\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_experience_list = df[ai_experience].tolist()\n",
    "prepare_for_ai_list = df[prepared_for_ai].tolist()\n",
    "discuss_jobs_list = df[discuss_jobs].tolist()\n",
    "prepared_for_internship_list = df[prepared_for_internship].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ai_experience_list = [item for item in ai_experience_list if not(pd.isnull(item)) == True]\n",
    "new_prepare_for_ai_list = [item for item in prepare_for_ai_list if not(pd.isnull(item)) == True]\n",
    "new_discuss_jobs_list = [item for item in discuss_jobs_list if not(pd.isnull(item)) == True]\n",
    "new_prepared_for_internship_list = [item for item in prepared_for_internship_list if not(pd.isnull(item)) == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "16\n",
      "24\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(new_ai_experience_list))\n",
    "print(len(new_prepare_for_ai_list))\n",
    "print(len(new_discuss_jobs_list))\n",
    "print(len(new_prepared_for_internship_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowercase_new_ai_experience_list = [ x.lower() for x in new_ai_experience_list ]\n",
    "lowercase_new_prepare_for_ai_list = [ x.lower() for x in new_prepare_for_ai_list ]\n",
    "lowercase_new_discuss_jobs_list = [ x.lower() for x in new_discuss_jobs_list ]\n",
    "lowercase_new_prepared_for_internship_list = [ x.lower() for x in new_prepared_for_internship_list ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "autospelled_lowercase_new_ai_experience_list = [ autospell(x) for x in lowercase_new_ai_experience_list ]\n",
    "autospelled_lowercase_new_prepare_for_ai_list = [ autospell(x) for x in lowercase_new_prepare_for_ai_list ]\n",
    "autospelled_lowercase_new_discuss_jobs_list = [ autospell(x) for x in lowercase_new_discuss_jobs_list ]\n",
    "autospelled_lowercase_new_prepared_for_internship_list = [ autospell(x) for x in lowercase_new_prepared_for_internship_list ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ai_experience = autospelled_lowercase_new_ai_experience_list\n",
    "final_prepare_for_ai = autospelled_lowercase_new_prepare_for_ai_list\n",
    "final_discuss_jobs = autospelled_lowercase_new_discuss_jobs_list\n",
    "final_prepared_for_internship = autospelled_lowercase_new_prepared_for_internship_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_experience_scores = [ te.get_emotion(x) for x in final_ai_experience ]\n",
    "prepare_for_ai_scores = [ te.get_emotion(x) for x in final_prepare_for_ai ]\n",
    "discuss_job_scores = [ te.get_emotion(x) for x in final_discuss_jobs ]\n",
    "prepared_for_internship_scores = [ te.get_emotion(x) for x in final_prepared_for_internship ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_experience_scores_df = pd.DataFrame(ai_experience_scores)\n",
    "prepare_for_ai_scores_df = pd.DataFrame(prepare_for_ai_scores)\n",
    "discuss_job_scores_df = pd.DataFrame(discuss_job_scores)\n",
    "prepared_for_internship_scores_df = pd.DataFrame(prepared_for_internship_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_emotion_average(list):\n",
    "    emotions = [\"Happy\", \"Angry\", \"Surprise\", \"Sad\", \"Fear\"]\n",
    "    ret = {}\n",
    "    \n",
    "    for e in emotions:\n",
    "        m = list[e].mean()\n",
    "        s = e\n",
    "        ret[s] = round(m, 3)\n",
    "    \n",
    "    return ret\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Experience {'Happy': 0.08, 'Angry': 0.0, 'Surprise': 0.14, 'Sad': 0.11, 'Fear': 0.31} \n",
      "\n",
      "Prepared for AI {'Happy': 0.012, 'Angry': 0.0, 'Surprise': 0.176, 'Sad': 0.128, 'Fear': 0.183} \n",
      "\n",
      "Discuss Job {'Happy': 0.172, 'Angry': 0.0, 'Surprise': 0.204, 'Sad': 0.188, 'Fear': 0.268} \n",
      "\n",
      "Prepared For Internship {'Happy': 0.1, 'Angry': 0.0, 'Surprise': 0.166, 'Sad': 0.1, 'Fear': 0.634} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"AI Experience\", prepare_emotion_average(ai_experience_scores_df), \"\\n\") \n",
    "print(\"Prepared for AI\", prepare_emotion_average(prepare_for_ai_scores_df), \"\\n\")\n",
    "print(\"Discuss Job\", prepare_emotion_average(discuss_job_scores_df), \"\\n\")\n",
    "print(\"Prepared For Internship\", prepare_emotion_average(prepared_for_internship_scores_df), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlk = \"I am happy to join with you today in what will go down in history as the greatest demonstration for freedom in the history of our nation.Five score years ago, a great American, in whose symbolic shadow we stand today, signed the Emancipation Proclamation. This momentous decree came as a great beacon light of hope to millions of Negro slaves who had been seared in the flames of withering injustice. It came as a joyous daybreak to end the long night of their captivity.But one hundred years later, the Negro still is not free. One hundred years later, the life of the Negro is still sadly crippled by the manacles of segregation and the chains of discrimination. One hundred years later, the Negro lives on a lonely island of poverty in the midst of a vast ocean of material prosperity. One hundred years later, the Negro is still languishing in the corners of American society and finds himself an exile in his own land. So we have come here today to dramatize a shameful condition.In a sense we have come to our nation's capital to cash a check. When the architects of our republic wrote the magnificent words of the Constitution and the Declaration of Independence, they were signing a promissory note to which every American was to fall heir. This note was a promise that all men, yes, black men as well as white men, would be guaranteed the unalienable rights of life, liberty, and the pursuit of happiness.It is obvious today that America has defaulted on this promissory note insofar as her citizens of color are concerned. Instead of honoring this sacred obligation, America has given the Negro people a bad check, a check which has come back marked insufficient funds. But we refuse to believe that the bank of justice is bankrupt. We refuse to believe that there are insufficient funds in the great vaults of opportunity of this nation. So we have come to cash this check -- a check that will give us upon demand the riches of freedom and the security of justice. We have also come to this hallowed spot to remind America of the fierce urgency of now. This is no time to engage in the luxury of cooling off or to take the tranquilizing drug of gradualism. Now is the time to make real the promises of democracy. Now is the time to rise from the dark and desolate valley of segregation to the sunlit path of racial justice. Now is the time to lift our nation from the quick sands of racial injustice to the solid rock of brotherhood. Now is the time to make justice a reality for all of God's children.It would be fatal for the nation to overlook the urgency of the moment. This sweltering summer of the Negro's legitimate discontent will not pass until there is an invigorating autumn of freedom and equality. Nineteen sixty-three is not an end, but a beginning. Those who hope that the Negro needed to blow off steam and will now be content will have a rude awakening if the nation returns to business as usual. There will be neither rest nor tranquility in America until the Negro is granted his citizenship rights. The whirlwinds of revolt will continue to shake the foundations of our nation until the bright day of justice emerges.But there is something that I must say to my people who stand on the warm threshold which leads into the palace of justice. In the process of gaining our rightful place we must not be guilty of wrongful deeds. Let us not seek to satisfy our thirst for freedom by drinking from the cup of bitterness and hatred.We must forever conduct our struggle on the high plane of dignity and discipline. We must not allow our creative protest to degenerate into physical violence. Again and again we must rise to the majestic heights of meeting physical force with soul force. The marvelous new militancy which has engulfed the Negro community must not lead us to a distrust of all white people, for many of our white brothers, as evidenced by their presence here today, have come to realize that their destiny is tied up with our destiny. They have come to realize that their freedom is inextricably bound to our freedom. We cannot walk alone.As we walk, we must make the pledge that we shall always march ahead. We cannot turn back. There are those who are asking the devotees of civil rights, When will you be satisfied? We can never be satisfied as long as the Negro is the victim of the unspeakable horrors of police brutality. We can never be satisfied, as long as our bodies, heavy with the fatigue of travel, cannot gain lodging in the motels of the highways and the hotels of the cities. We cannot be satisfied as long as the Negro's basic mobility is from a smaller ghetto to a larger one. We can never be satisfied as long as our children are stripped of their selfhood and robbed of their dignity by signs stating For Whites Only. We cannot be satisfied as long as a Negro in Mississippi cannot vote and a Negro in New York believes he has nothing for which to vote. No, no, we are not satisfied, and we will not be satisfied until justice rolls down like waters and righteousness like a mighty stream.I am not unmindful that some of you have come here out of great trials and tribulations. Some of you have come fresh from narrow jail cells. Some of you have come from areas where your quest for freedom left you battered by the storms of persecution and staggered by the winds of police brutality. You have been the veterans of creative suffering. Continue to work with the faith that unearned suffering is redemptive.Go back to Mississippi, go back to Alabama, go back to South Carolina, go back to Georgia, go back to Louisiana, go back to the slums and ghettos of our northern cities, knowing that somehow this situation can and will be changed. Let us not wallow in the valley of despair.I say to you today, my friends, so even though we face the difficulties of today and tomorrow, I still have a dream. It is a dream deeply rooted in the American dream.I have a dream that one day this nation will rise up and live out the true meaning of its creed: We hold these truths to be self-evident: that all men are created equal.I have a dream that one day on the red hills of Georgia the sons of former slaves and the sons of former slave owners will be able to sit down together at the table of brotherhood.I have a dream that one day even the state of Mississippi, a state sweltering with the heat of injustice, sweltering with the heat of oppression, will be transformed into an oasis of freedom and justice.I have a dream that my four little children will one day live in a nation where they will not be judged by the color of their skin but by the content of their character.I have a dream today.I have a dream that one day, down in Alabama, with its vicious racists, with its governor having his lips dripping with the words of interposition and nullification; one day right there in Alabama, little black boys and black girls will be able to join hands with little white boys and white girls as sisters and brothers.I have a dream today.I have a dream that one day every valley shall be exalted, every hill and mountain shall be made low, the rough places will be made plain, and the crooked places will be made straight, and the glory of the Lord shall be revealed, and all flesh shall see it together.This is our hope. This is the faith that I go back to the South with. With this faith we will be able to hew out of the mountain of despair a stone of hope. With this faith we will be able to transform the jangling discords of our nation into a beautiful symphony of brotherhood. With this faith we will be able to work together, to pray together, to struggle together, to go to jail together, to stand up for freedom together, knowing that we will be free one day.This will be the day when all of God's children will be able to sing with a new meaning, My country, 'tis of thee, sweet land of liberty, of thee I sing. Land where my fathers died, land of the pilgrim's pride, from every mountainside, let freedom ring.And if America is to be a great nation this must become true. So let freedom ring from the prodigious hilltops of New Hampshire. Let freedom ring from the mighty mountains of New York. Let freedom ring from the heightening Alleghenies of Pennsylvania!Let freedom ring from the snowcapped Rockies of Colorado!Let freedom ring from the curvaceous slopes of California!But not only that; let freedom ring from Stone Mountain of Georgia!Let freedom ring from Lookout Mountain of Tennessee!Let freedom ring from every hill and molehill of Mississippi. From every mountainside, let freedom ring.And when this happens, when we allow freedom to ring, when we let it ring from every village and every hamlet, from every state and every city, we will be able to speed up that day when all of God's children, black men and white men, Jews and Gentiles, Protestants and Catholics, will be able to join hands and sing in the words of the old Negro spiritual, Free at last! free at last! thank God Almighty, we are free at last!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Happy': 0.15, 'Angry': 0.05, 'Surprise': 0.13, 'Sad': 0.25, 'Fear': 0.41}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te.get_emotion(mlk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = df[\"Name\"]\n",
    "python = df[\"Based on your experience, how important are these skill sets to go into AI jobs? [Python]\"]\n",
    "javascript = df[\"Based on your experience, how important are these skill sets to go into AI jobs? [Javascript]\"]\n",
    "java = df[\"Based on your experience, how important are these skill sets to go into AI jobs? [Java]\"]\n",
    "sql = df[\"Based on your experience, how important are these skill sets to go into AI jobs? [SQL]\"]\n",
    "r = df[\"Based on your experience, how important are these skill sets to go into AI jobs? [R]\"]\n",
    "cplus = df[\"Based on your experience, how important are these skill sets to go into AI jobs? [C++]\"]\n",
    "shell = df[\"Based on your experience, how important are these skill sets to go into AI jobs? [Shell Scripting]\"]\n",
    "kcluster = df[\"Based on your experience, how important are these skill sets to go into AI jobs? [K Cluster Analysis]\"]\n",
    "signal = df[\"Based on your experience, how important are these skill sets to go into AI jobs? [Signal Processing]\"]\n",
    "deeplearn = df[\"Based on your experience, how important are these skill sets to go into AI jobs? [Deep Learning]\"]\n",
    "calc = df[\"Based on your experience, how important are these skill sets to go into AI jobs? [Calculus]\"]\n",
    "probstats = df[\"Based on your experience, how important are these skill sets to go into AI jobs? [Probability and Statistics]\"]\n",
    "linearalg = df[\"Based on your experience, how important are these skill sets to go into AI jobs? [Linear Algebra]\"]\n",
    "graphanalysis = df[\"Based on your experience, how important are these skill sets to go into AI jobs? [Graph Analysis]\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_columns = [python, javascript, java, sql, r, cplus, shell, kcluster, signal, deeplearn, calc, probstats, linearalg, graphanalysis]\n",
    "\n",
    "idk = \"Don't Know What This Is\"\n",
    "nr = \"No Relevance\"\n",
    "low = \"Low Importance\"\n",
    "high = \"High Importance\"\n",
    "crucial = \"100% Crucial\"\n",
    "\n",
    "for list in list_of_columns:\n",
    "    list.replace(idk, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores has 4 values\n",
    "def replace_values(li, scores):\n",
    "    li = li.replace(nr, scores[0])\n",
    "    li = li.replace(low, scores[1])\n",
    "    li = li.replace(high, scores[2])\n",
    "    li = li.replace(crucial, scores[3])\n",
    "    return li\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "python = replace_values(python, [0, .3, .6, 1])\n",
    "javascript = replace_values(javascript, [.3, 1, .3, 0])\n",
    "java = replace_values(java, [.3, 1, .3, 0])\n",
    "sql = replace_values(sql, [0, .3, 1, .3])\n",
    "r = replace_values(r, [0, .3, 1, .3])\n",
    "cplus = replace_values(cplus, [.3, 1, .3, 0])\n",
    "shell = replace_values(shell, [.3, 1, .3, 0])\n",
    "kcluster = replace_values(kcluster, [0, .3, 1, .3])\n",
    "signal = replace_values(signal, [.3, 1, .3, 0])\n",
    "deeplearn = replace_values(deeplearn, [0, .3, 1, .3])\n",
    "calc = replace_values(calc, [1, .3, .3, 0])\n",
    "probstats = replace_values(probstats, [0, .3, .6, 1])\n",
    "linearalg = replace_values(linearalg, [.3, 1, .3, 0])\n",
    "graphanalysis = replace_values(graphanalysis, [.3, 1, .3, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(columns=['name', 'python', 'javascript', 'java', 'sql', 'r', 'cplus', 'shell', 'kcluster', 'signal', 'deeplearn', 'calc', 'probstats', 'linearalg', 'graphanalysis'])\n",
    "df_test[\"name\"] = names\n",
    "df_test[\"python\"] = python\n",
    "df_test['javascript'] = javascript\n",
    "df_test[\"java\"] = java\n",
    "df_test['sql'] = sql\n",
    "df_test[\"r\"] = r\n",
    "df_test['cplus'] = cplus\n",
    "df_test[\"shell\"] = shell\n",
    "df_test['kcluster'] = kcluster\n",
    "df_test[\"signal\"] = signal\n",
    "df_test['deeplearn'] = deeplearn\n",
    "df_test[\"calc\"] = calc\n",
    "df_test['probstats'] = probstats\n",
    "df_test['linearalg'] = probstats\n",
    "df_test['graphanalysis'] = probstats\n",
    "\n",
    "df_test = df_test.replace(\"Don't Know What This Is\", 0)\n",
    "df_test[\"QUIZ SCORE\"] = df_test.sum(axis=1)\n",
    "df[\"quiz score\"] = df_test[\"QUIZ SCORE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# winners\n",
    "df_test_sorted = df_test.sort_values('QUIZ SCORE', ascending=False)\n",
    "winning_population_names = df_test_sorted[:27][\"name\"]\n",
    "df_test_sorted = df_test.sort_values('QUIZ SCORE', ascending=True)\n",
    "losing_population_names = df_test_sorted[:38][\"name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Winner', 'Loser', 'Winner', 'Winner', 'Winner', 'Winner', 'Loser', 'Winner', 'Loser', 'Loser', 'Winner', 'Loser', 'Winner', 'Winner', 'Loser', 'Winner', 'Winner', 'Loser', 'Loser', 'Winner', 'Winner', 'Winner', 'Loser', 'Winner', 'Loser', 'Loser', 'Loser', 'Winner', 'Winner', 'Loser', 'Winner', 'Loser', 'Loser', 'Loser', 'Loser', 'Winner', 'Winner', 'Winner', 'Loser', 'Loser', 'Winner', 'Loser', 'Loser', 'Loser', 'Winner', 'Loser', 'Loser', 'Loser', 'Loser', 'Winner', 'Loser', 'Loser', 'Winner', 'Loser', 'Loser', 'Loser', 'Loser', 'Loser', 'Loser', 'Loser', 'Loser', 'Winner', 'Loser', 'Loser', 'Winner']\n"
     ]
    }
   ],
   "source": [
    "win_list = []\n",
    "list_of_winners = winning_population_names.tolist()\n",
    "for name in df[\"Name\"]:\n",
    "    if name in list_of_winners:\n",
    "        win_list.append(\"Winner\")\n",
    "    else:\n",
    "        win_list.append(\"Loser\")\n",
    "print(win_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(winning_population_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Winner\n",
       "1      Loser\n",
       "2     Winner\n",
       "3     Winner\n",
       "4     Winner\n",
       "       ...  \n",
       "60     Loser\n",
       "61    Winner\n",
       "62     Loser\n",
       "63     Loser\n",
       "64    Winner\n",
       "Length: 65, dtype: object"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_winners = pd.Series(win_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Win Status\"] = add_winners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>On a high level, please rank your familiarity with AI as an industry</th>\n",
       "      <th>If you would like, please describe your experience with AI or knowledge surrounding it</th>\n",
       "      <th>Alphabet (Google)</th>\n",
       "      <th>General Motors</th>\n",
       "      <th>IBM</th>\n",
       "      <th>Palantir Technologies</th>\n",
       "      <th>Meta (Facebook)</th>\n",
       "      <th>Johnson &amp; Johnson</th>\n",
       "      <th>Novartis</th>\n",
       "      <th>...</th>\n",
       "      <th>University</th>\n",
       "      <th>Major</th>\n",
       "      <th>Age At Time Of Taking this Survey</th>\n",
       "      <th>Undergrad Graduation Year</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Race</th>\n",
       "      <th>Email</th>\n",
       "      <th>quiz score</th>\n",
       "      <th>Win Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Example for Professor</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>Northeastern</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>21</td>\n",
       "      <td>2022</td>\n",
       "      <td>Male</td>\n",
       "      <td>Not hispanic or Latino</td>\n",
       "      <td>Asian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Winner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ria bajaj</td>\n",
       "      <td>2</td>\n",
       "      <td>ive heard of it</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>Northeastern</td>\n",
       "      <td>Economics</td>\n",
       "      <td>22</td>\n",
       "      <td>2022</td>\n",
       "      <td>Female</td>\n",
       "      <td>Not hispanic or Latino</td>\n",
       "      <td>Asian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Loser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vrishin Sundaram</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>BU</td>\n",
       "      <td>Engineering (Other)</td>\n",
       "      <td>19</td>\n",
       "      <td>2024</td>\n",
       "      <td>Male</td>\n",
       "      <td>Not hispanic or Latino</td>\n",
       "      <td>Asian</td>\n",
       "      <td>vrishin@bu.edu</td>\n",
       "      <td>8.2</td>\n",
       "      <td>Winner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vidhan Sethi</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>BU</td>\n",
       "      <td>Business (Other)</td>\n",
       "      <td>19</td>\n",
       "      <td>2025</td>\n",
       "      <td>Male</td>\n",
       "      <td>Not hispanic or Latino</td>\n",
       "      <td>Asian</td>\n",
       "      <td>sethividhan@gmail.com</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Winner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arya Shukla</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Northeastern</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>20</td>\n",
       "      <td>2024</td>\n",
       "      <td>Female</td>\n",
       "      <td>Not hispanic or Latino</td>\n",
       "      <td>Asian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.3</td>\n",
       "      <td>Winner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Aparna Shanmugam</td>\n",
       "      <td>3</td>\n",
       "      <td>My dad works in AI and I know it’s artificial ...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>Northeastern</td>\n",
       "      <td>Cybersecurity</td>\n",
       "      <td>19</td>\n",
       "      <td>2025</td>\n",
       "      <td>Female</td>\n",
       "      <td>Not hispanic or Latino</td>\n",
       "      <td>Asian</td>\n",
       "      <td>shanmugam.a@northeastern.edu</td>\n",
       "      <td>6.1</td>\n",
       "      <td>Loser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Srijay Kasturi</td>\n",
       "      <td>4</td>\n",
       "      <td>it’s cool</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>umd</td>\n",
       "      <td>philosophy</td>\n",
       "      <td>21</td>\n",
       "      <td>2023</td>\n",
       "      <td>Male</td>\n",
       "      <td>Not hispanic or Latino</td>\n",
       "      <td>Asian</td>\n",
       "      <td>srijaykasturi@gmail.com</td>\n",
       "      <td>10.5</td>\n",
       "      <td>Winner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>karan desai</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Uiuc</td>\n",
       "      <td>Business (Finance)</td>\n",
       "      <td>23</td>\n",
       "      <td>2022</td>\n",
       "      <td>Male</td>\n",
       "      <td>Not hispanic or Latino</td>\n",
       "      <td>Asian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.7</td>\n",
       "      <td>Loser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Maya Gogia</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>BU</td>\n",
       "      <td>Business (Other)</td>\n",
       "      <td>23</td>\n",
       "      <td>2020</td>\n",
       "      <td>Female</td>\n",
       "      <td>Hispanic or latino</td>\n",
       "      <td>Asian</td>\n",
       "      <td>mayagogia22@gmail.com</td>\n",
       "      <td>5.8</td>\n",
       "      <td>Loser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>roshan</td>\n",
       "      <td>3</td>\n",
       "      <td>Limited.</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>BU</td>\n",
       "      <td>Business (Finance)</td>\n",
       "      <td>24</td>\n",
       "      <td>2020</td>\n",
       "      <td>Male</td>\n",
       "      <td>Not hispanic or Latino</td>\n",
       "      <td>Asian, Indian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.2</td>\n",
       "      <td>Winner</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Name  \\\n",
       "0   Example for Professor   \n",
       "1               ria bajaj   \n",
       "2       Vrishin Sundaram    \n",
       "3            Vidhan Sethi   \n",
       "4             Arya Shukla   \n",
       "..                    ...   \n",
       "60      Aparna Shanmugam    \n",
       "61         Srijay Kasturi   \n",
       "62           karan desai    \n",
       "63             Maya Gogia   \n",
       "64                roshan    \n",
       "\n",
       "    On a high level, please rank your familiarity with AI as an industry  \\\n",
       "0                                                   3                      \n",
       "1                                                   2                      \n",
       "2                                                   4                      \n",
       "3                                                   4                      \n",
       "4                                                   4                      \n",
       "..                                                ...                      \n",
       "60                                                  3                      \n",
       "61                                                  4                      \n",
       "62                                                  4                      \n",
       "63                                                  3                      \n",
       "64                                                  3                      \n",
       "\n",
       "   If you would like, please describe your experience with AI or knowledge surrounding it  \\\n",
       "0                                                 NaN                                       \n",
       "1                                     ive heard of it                                       \n",
       "2                                                 NaN                                       \n",
       "3                                                 NaN                                       \n",
       "4                                                 NaN                                       \n",
       "..                                                ...                                       \n",
       "60  My dad works in AI and I know it’s artificial ...                                       \n",
       "61                                          it’s cool                                       \n",
       "62                                                NaN                                       \n",
       "63                                                NaN                                       \n",
       "64                                          Limited.                                        \n",
       "\n",
       "    Alphabet (Google)  General Motors  IBM  Palantir Technologies  \\\n",
       "0                   3               3    3                      3   \n",
       "1                   5               5    5                      1   \n",
       "2                   4               5    4                      5   \n",
       "3                   4               4    5                      1   \n",
       "4                   1               4    4                      1   \n",
       "..                ...             ...  ...                    ...   \n",
       "60                  5               5    3                      3   \n",
       "61                  5               4    4                      4   \n",
       "62                  5               4    4                      4   \n",
       "63                  4               3    3                      2   \n",
       "64                  5               5    5                      5   \n",
       "\n",
       "    Meta (Facebook)  Johnson & Johnson   Novartis  ...    University  \\\n",
       "0                 3                   3         3  ...  Northeastern   \n",
       "1                 5                   5         4  ...  Northeastern   \n",
       "2                 4                   4         5  ...            BU   \n",
       "3                 5                   5         1  ...            BU   \n",
       "4                 1                   5         1  ...  Northeastern   \n",
       "..              ...                 ...       ...  ...           ...   \n",
       "60                5                   5         3  ...  Northeastern   \n",
       "61                5                   3         1  ...           umd   \n",
       "62                5                   4         1  ...          Uiuc   \n",
       "63                4                   3         3  ...            BU   \n",
       "64                5                   5         5  ...            BU   \n",
       "\n",
       "                  Major  Age At Time Of Taking this Survey  \\\n",
       "0      Computer Science                                 21   \n",
       "1             Economics                                 22   \n",
       "2   Engineering (Other)                                 19   \n",
       "3      Business (Other)                                 19   \n",
       "4          Data Science                                 20   \n",
       "..                  ...                                ...   \n",
       "60        Cybersecurity                                 19   \n",
       "61           philosophy                                 21   \n",
       "62   Business (Finance)                                 23   \n",
       "63     Business (Other)                                 23   \n",
       "64   Business (Finance)                                 24   \n",
       "\n",
       "    Undergrad Graduation Year     Sex               Ethnicity           Race  \\\n",
       "0                        2022    Male  Not hispanic or Latino          Asian   \n",
       "1                        2022  Female  Not hispanic or Latino          Asian   \n",
       "2                        2024    Male  Not hispanic or Latino          Asian   \n",
       "3                        2025    Male  Not hispanic or Latino          Asian   \n",
       "4                        2024  Female  Not hispanic or Latino          Asian   \n",
       "..                        ...     ...                     ...            ...   \n",
       "60                       2025  Female  Not hispanic or Latino          Asian   \n",
       "61                       2023    Male  Not hispanic or Latino          Asian   \n",
       "62                       2022    Male  Not hispanic or Latino          Asian   \n",
       "63                       2020  Female      Hispanic or latino          Asian   \n",
       "64                       2020    Male  Not hispanic or Latino  Asian, Indian   \n",
       "\n",
       "                           Email  quiz score  Win Status  \n",
       "0                            NaN         7.7      Winner  \n",
       "1                            NaN         6.0       Loser  \n",
       "2                 vrishin@bu.edu         8.2      Winner  \n",
       "3          sethividhan@gmail.com         8.0      Winner  \n",
       "4                            NaN        10.3      Winner  \n",
       "..                           ...         ...         ...  \n",
       "60  shanmugam.a@northeastern.edu         6.1       Loser  \n",
       "61       srijaykasturi@gmail.com        10.5      Winner  \n",
       "62                           NaN         6.7       Loser  \n",
       "63         mayagogia22@gmail.com         5.8       Loser  \n",
       "64                           NaN        10.2      Winner  \n",
       "\n",
       "[65 rows x 77 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
